import streamlit as st
import json
import requests
import openai
import speech_recognition as sr
import io
import tempfile
from datetime import datetime
from typing import List, Dict, Optional
from pydantic import BaseModel, Field
import google.generativeai as genai
from langchain_community.utilities import SerpAPIWrapper
from langchain_community.utilities import BingSearchAPIWrapper
import whisper
import numpy as np
from audio_recorder_streamlit import audio_recorder

# Configure page
st.set_page_config(
    page_title="CodeXR - AI Coding Assistant for AR/VR Developers",
    page_icon="ü•Ω",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for developer-friendly styling
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .demo-card {
        border: 2px solid #e1e5e9;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        background: #f8f9fa;
        cursor: pointer;
        transition: all 0.3s;
    }
    .demo-card:hover {
        border-color: #667eea;
        background: #e3f2fd;
    }
    .subtask-item {
        background: #f0f4f8;
        border-left: 4px solid #667eea;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
    }
    .code-block {
        background: #2d3748;
        color: #e2e8f0;
        padding: 1rem;
        border-radius: 5px;
        font-family: 'Fira Code', monospace;
    }
    .best-practice {
        background: #f0fff4;
        border-left: 4px solid #48bb78;
        padding: 0.8rem;
        margin: 0.3rem 0;
        border-radius: 3px;
    }
    .gotcha {
        background: #fffbf0;
        border-left: 4px solid #ed8936;
        padding: 0.8rem;
        margin: 0.3rem 0;
        border-radius: 3px;
    }
    .difficulty-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.875rem;
        font-weight: bold;
        margin: 0.25rem;
    }
    .difficulty-1 { background: #c6f6d5; color: #276749; }
    .difficulty-2 { background: #bee3f8; color: #2a69ac; }
    .difficulty-3 { background: #feebc8; color: #c05621; }
    .difficulty-4 { background: #fed7d7; color: #c53030; }
    .difficulty-5 { background: #e9d8fd; color: #553c9a; }
    .success-criteria {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Data Models
class SubTask(BaseModel):
    description: str
    code_snippet: Optional[str] = None
    explanation: Optional[str] = None

class CodeXRResponse(BaseModel):
    query: str
    category: str
    subtasks: List[SubTask]
    code_snippet: str
    best_practices: List[str]
    gotchas: List[str]
    difficulty_rating: int = Field(ge=1, le=5)
    documentation_links: List[str]
    estimated_time: str
    raw_json: Dict

# Configuration
class Config:
    GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
    OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")
    SERP_API_KEY = st.secrets.get("SERP_API_KEY", "")
    BING_API_KEY = st.secrets.get("BING_SEARCH_KEY", "")

# Initialize APIs
@st.cache_resource
def initialize_apis():
    config = Config()
    
    # Initialize Gemini
    if config.GEMINI_API_KEY:
        genai.configure(api_key=config.GEMINI_API_KEY)
    
    # Initialize OpenAI
    if config.OPENAI_API_KEY:
        openai.api_key = config.OPENAI_API_KEY
    
    # Initialize search engines
    search_engines = {}
    if config.SERP_API_KEY:
        search_engines['serp'] = SerpAPIWrapper(serpapi_api_key=config.SERP_API_KEY)
    if config.BING_API_KEY:
        search_engines['bing'] = BingSearchAPIWrapper(bing_subscription_key=config.BING_API_KEY)
    
    return search_engines

# Demo Knowledge Base
DEMO_KNOWLEDGE = {
    "Unity": {
        "teleport": {
            "subtasks": [
                {
                    "description": "Install XR Interaction Toolkit",
                    "code_snippet": "// Window > Package Manager > Unity Registry > XR Interaction Toolkit",
                    "explanation": "The XR Interaction Toolkit provides the foundation for VR interactions including teleportation"
                },
                {
                    "description": "Create XR Origin (Camera Rig)",
                    "code_snippet": "// GameObject > XR > XR Origin (VR)",
                    "explanation": "XR Origin manages the VR camera and tracking space for your player"
                },
                {
                    "description": "Add Teleportation Provider",
                    "code_snippet": "GetComponent<TeleportationProvider>()",
                    "explanation": "The Teleportation Provider handles the actual teleportation logic and validation"
                },
                {
                    "description": "Configure Teleport Areas",
                    "code_snippet": "// Add Component > XR > Teleportation Area",
                    "explanation": "Define which surfaces or locations players can teleport to"
                }
            ],
            "main_code": """using UnityEngine;
using UnityEngine.XR.Interaction.Toolkit;

public class TeleportSetup : MonoBehaviour
{
    public TeleportationProvider teleportProvider;
    public XRRayInteractor rayInteractor;
    public LineRenderer teleportLine;
    
    void Start()
    {
        // Configure teleportation provider
        if (teleportProvider == null)
            teleportProvider = FindObjectOfType<TeleportationProvider>();
            
        // Setup ray interactor for teleportation
        if (rayInteractor != null)
        {
            rayInteractor.enableUIInteraction = false;
            rayInteractor.lineType = XRRayInteractor.LineType.ProjectileCurve;
            rayInteractor.maxRaycastDistance = 10f;
        }
        
        // Configure visual feedback
        if (teleportLine != null)
        {
            teleportLine.material.color = Color.cyan;
            teleportLine.width = 0.02f;
        }
    }
    
    // Optional: Custom teleport validation
    public bool ValidateTeleportRequest(TeleportRequest request)
    {
        return request.destinationPosition.y >= -1f; // Prevent teleporting too low
    }
}""",
            "best_practices": [
                "Use NavMesh for teleportation boundaries to prevent players from teleporting into walls",
                "Provide clear visual feedback with arc lines showing valid teleport destinations",
                "Consider comfort settings like fade transitions to reduce motion sickness",
                "Test teleportation on different VR headsets for compatibility and comfort",
                "Use Teleportation Anchors for precise positioning at important locations",
                "Implement audio feedback for successful teleportation"
            ],
            "gotchas": [
                "Ensure TeleportationProvider is assigned in the scene hierarchy",
                "NavMesh must be baked for ground-based teleportation to work properly",
                "Ray interactor may conflict with UI interactions - disable UI interaction when needed",
                "Performance impact on mobile VR platforms - optimize teleport arc calculations",
                "Teleport areas need proper colliders to be detected by the ray interactor",
                "Layer masks can prevent teleportation - check your layer settings"
            ],
            "docs": [
                "https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit@2.5/manual/teleportation.html",
                "https://docs.unity3d.com/Manual/nav-BuildingNavMesh.html",
                "https://learn.unity.com/tutorial/vr-best-practices"
            ]
        }
    },
    "Unreal": {
        "multiplayer": {
            "subtasks": [
                {
                    "description": "Enable VR Template",
                    "code_snippet": "// Create new project with VR Template",
                    "explanation": "Start with VR-ready project setup including motion controller support"
                },
                {
                    "description": "Configure Network Settings",
                    "code_snippet": "// Project Settings > Engine > Network",
                    "explanation": "Configure basic networking settings for multiplayer support"
                },
                {
                    "description": "Setup Custom Game Mode",
                    "code_snippet": "// Create custom VRGameMode class",
                    "explanation": "Custom game mode handles player spawning and VR-specific multiplayer logic"
                },
                {
                    "description": "Implement Player Replication",
                    "code_snippet": "// Configure pawn replication",
                    "explanation": "Ensure VR player movements and interactions are synchronized across clients"
                }
            ],
            "main_code": """// VRGameMode.h
#pragma once

#include "CoreMinimal.h"
#include "GameFramework/GameModeBase.h"
#include "VRGameMode.generated.h"

UCLASS()
class VRGAME_API AVRGameMode : public AGameModeBase
{
    GENERATED_BODY()
    
public:
    AVRGameMode();
    
protected:
    virtual void PostLogin(APlayerController* NewPlayer) override;
    virtual void Logout(AController* Exiting) override;
    
    UPROPERTY(EditDefaultsOnly, BlueprintReadOnly, Category = "VR Settings")
    int32 MaxPlayers = 4;
    
    UPROPERTY(EditDefaultsOnly, BlueprintReadOnly, Category = "VR Settings")
    bool bEnableHandTracking = true;
};

// VRGameMode.cpp
#include "VRGameMode.h"
#include "VRPlayerController.h"
#include "VRPawn.h"

AVRGameMode::AVRGameMode()
{
    DefaultPawnClass = AVRPawn::StaticClass();
    PlayerControllerClass = AVRPlayerController::StaticClass();
    
    // Enable replication
    bReplicates = true;
}

void AVRGameMode::PostLogin(APlayerController* NewPlayer)
{
    Super::PostLogin(NewPlayer);
    
    UE_LOG(LogTemp, Log, TEXT("VR Player joined session: %s"), 
           *NewPlayer->GetName());
    
    // Setup VR-specific player initialization
    if (AVRPlayerController* VRController = Cast<AVRPlayerController>(NewPlayer))
    {
        VRController->SetupVRPlayer();
    }
}""",
            "best_practices": [
                "Use dedicated servers for stable multiplayer VR experiences",
                "Implement proper VR controller and hand tracking replication",
                "Optimize network traffic for VR-specific data (head position, hand poses)",
                "Handle VR-specific player disconnections gracefully with comfort transitions",
                "Use Unreal's built-in VR optimization features for multiplayer",
                "Implement spatial audio for better multiplayer immersion"
            ],
            "gotchas": [
                "VR pawns require special network setup - not all components replicate by default",
                "Hand tracking data needs careful replication to avoid network spam",
                "Locomotion systems can cause network prediction issues in multiplayer",
                "Performance drops significantly with multiple VR players - optimize rendering",
                "VR comfort settings may conflict with multiplayer synchronization",
                "Mobile VR platforms have additional networking limitations"
            ],
            "docs": [
                "https://docs.unrealengine.com/5.0/en-us/multiplayer-programming-quick-start-for-unreal-engine/",
                "https://docs.unrealengine.com/5.0/en-us/vr-development-in-unreal-engine/",
                "https://docs.unrealengine.com/5.0/en-us/networking-and-multiplayer-in-unreal-engine/"
            ]
        }
    },
    "Shader": {
        "occlusion": {
            "subtasks": [
                {
                    "description": "Create Occlusion Shader",
                    "code_snippet": "// Shader > Create > Unlit Shader",
                    "explanation": "Occlusion shaders need to write to depth buffer without rendering visible pixels"
                },
                {
                    "description": "Configure Depth Testing",
                    "code_snippet": "// ZWrite On, ZTest LEqual, ColorMask 0",
                    "explanation": "Proper depth buffer configuration is critical for AR occlusion"
                },
                {
                    "description": "Implement Alpha Blending",
                    "code_snippet": "// Blend SrcAlpha OneMinusSrcAlpha",
                    "explanation": "Alpha blending allows for soft occlusion effects"
                },
                {
                    "description": "Optimize for Mobile AR",
                    "code_snippet": "// Use simple vertex/fragment operations",
                    "explanation": "Mobile AR platforms have limited GPU resources"
                }
            ],
            "main_code": """Shader "AR/OcclusionShader"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        _Alpha ("Alpha", Range(0,1)) = 0.0
        _OcclusionStrength ("Occlusion Strength", Range(0,1)) = 1.0
    }
    
    SubShader
    {
        Tags { 
            "RenderType"="Transparent" 
            "Queue"="Geometry-1" 
            "ForceNoShadowCasting"="True"
        }
        
        LOD 100
        
        // First pass: Write to depth buffer only
        Pass
        {
            Name "OCCLUSION"
            ZWrite On
            ZTest LEqual
            ColorMask 0
            Cull Off
            
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #pragma target 2.0
            
            #include "UnityCG.cginc"
            
            struct appdata
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };
            
            struct v2f
            {
                float4 vertex : SV_POSITION;
                float2 uv : TEXCOORD0;
            };
            
            v2f vert (appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                return o;
            }
            
            fixed4 frag (v2f i) : SV_Target
            {
                // Only write to depth, no color output
                return fixed4(0,0,0,0);
            }
            ENDCG
        }
    }
    
    FallBack "Mobile/Diffuse"
}""",
            "best_practices": [
                "Use depth-only rendering for better performance - avoid unnecessary color calculations",
                "Implement proper depth buffer management with ZWrite On and ZTest LEqual",
                "Consider mobile GPU limitations when designing occlusion shaders",
                "Test with different AR tracking systems (ARCore, ARKit) for compatibility",
                "Use render queue 'Geometry-1' to ensure occlusion renders before other objects",
                "Implement LOD system for complex occlusion geometry"
            ],
            "gotchas": [
                "Render queue order is critical - wrong queue can break occlusion completely",
                "Mobile GPUs may have depth precision issues causing z-fighting",
                "Alpha blending can cause sorting problems with transparent objects",
                "Performance impact on older mobile devices - test thoroughly",
                "Some AR frameworks require specific shader tags or properties",
                "Depth buffer sharing between AR camera and Unity can cause conflicts"
            ],
            "docs": [
                "https://docs.unity3d.com/Manual/SL-ShaderReplacement.html",
                "https://developers.google.com/ar/develop/unity/occlusion",
                "https://developer.apple.com/documentation/arkit/environmental_analysis/occluding_virtual_content_with_people"
            ]
        }
    }
}

def categorize_query(query: str) -> str:
    """Categorize queries into Unity/Unreal/Shader/General"""
    query_lower = query.lower()
    
    unity_keywords = ["unity", "c#", "xr toolkit", "teleport", "vr", "ar", "interaction", "gameobject"]
    unreal_keywords = ["unreal", "c++", "ue4", "ue5", "blueprint", "multiplayer", "uclass", "generated_body"]
    shader_keywords = ["shader", "hlsl", "glsl", "material", "rendering", "occlusion", "vertex", "fragment"]
    
    unity_score = sum(1 for keyword in unity_keywords if keyword in query_lower)
    unreal_score = sum(1 for keyword in unreal_keywords if keyword in query_lower)
    shader_score = sum(1 for keyword in shader_keywords if keyword in query_lower)
    
    scores = {"Unity": unity_score, "Unreal": unreal_score, "Shader": shader_score}
    max_category = max(scores, key=scores.get)
    
    return max_category if scores[max_category] > 0 else "General"

def search_documentation(query: str, search_engines: dict) -> List[str]:
    """Search for relevant documentation using web search agents"""
    results = []
    
    search_query = f"AR VR development {query} official documentation tutorial"
    
    try:
        if 'serp' in search_engines:
            serp_results = search_engines['serp'].run(search_query)
            results.append(f"Search Results: {serp_results}")
        elif 'bing' in search_engines:
            bing_results = search_engines['bing'].run(search_query)
            results.append(f"Search Results: {bing_results}")
    except Exception as e:
        st.warning(f"Web search unavailable: {e}")
        results.append("Web search temporarily unavailable - using cached knowledge")
    
    return results

def process_with_llm(query: str, category: str, search_results: List[str], llm_choice: str) -> CodeXRResponse:
    """Process query with selected LLM backend"""
    
    # Check if it's a demo scenario
    demo_response = get_demo_response(query, category)
    if demo_response:
        return demo_response
    
    # Context for LLM
    context = f"""
    You are CodeXR, an AI coding assistant for AR/VR developers.
    
    Query: {query}
    Category: {category}
    Search Context: {' '.join(search_results)}
    
    Provide a structured response with:
    1. Step-by-step subtasks
    2. Production-ready code snippet
    3. Best practices
    4. Common gotchas/pitfalls
    5. Difficulty rating (1-5)
    6. Estimated time
    7. Documentation links
    """
    
    try:
        if llm_choice == "Gemini 2.5" and Config.GEMINI_API_KEY:
            response = process_with_gemini(context, query, category)
        elif llm_choice == "GPT-4o-mini" and Config.OPENAI_API_KEY:
            response = process_with_openai(context, query, category)
        else:
            # Fallback to demo knowledge or basic response
            response = generate_fallback_response(query, category)
            
        return response
        
    except Exception as e:
        st.error(f"LLM processing error: {e}")
        return generate_fallback_response(query, category)

def process_with_gemini(context: str, query: str, category: str) -> CodeXRResponse:
    """Process with Gemini 2.5"""
    model = genai.GenerativeModel('gemini-pro')
    
    prompt = f"""
    {context}
    
    Respond in this exact JSON format:
    {{
        "query": "{query}",
        "category": "{category}",
        "subtasks": [
            {{"description": "...", "code_snippet": "...", "explanation": "..."}}
        ],
        "code_snippet": "...",
        "best_practices": ["..."],
        "gotchas": ["..."],
        "difficulty_rating": 1-5,
        "documentation_links": ["..."],
        "estimated_time": "..."
    }}
    """
    
    response = model.generate_content(prompt)
    
    try:
        response_json = json.loads(response.text)
        return create_codexr_response(response_json)
    except:
        return generate_fallback_response(query, category)

def process_with_openai(context: str, query: str, category: str) -> CodeXRResponse:
    """Process with GPT-4o-mini"""
    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are CodeXR, an AI coding assistant for AR/VR developers."},
            {"role": "user", "content": context}
        ],
        temperature=0.7
    )
    
    try:
        response_text = response.choices[0].message.content
        response_json = json.loads(response_text)
        return create_codexr_response(response_json)
    except:
        return generate_fallback_response(query, category)

def get_demo_response(query: str, category: str) -> Optional[CodeXRResponse]:
    """Get response for demo scenarios"""
    query_lower = query.lower()
    
    if category in DEMO_KNOWLEDGE:
        for key, data in DEMO_KNOWLEDGE[category].items():
            if key in query_lower:
                return create_demo_response(query, category, data)
    
    return None

def create_demo_response(query: str, category: str, data: dict) -> CodeXRResponse:
    """Create CodeXR response from demo data"""
    subtasks = [SubTask(**task) for task in data["subtasks"]]
    
    raw_json = {
        "query": query,
        "category": category,
        "subtasks": [task.dict() for task in subtasks],
        "code_snippet": data["main_code"],
        "best_practices": data["best_practices"],
        "gotchas": data["gotchas"],
        "difficulty_rating": 4 if category == "Shader" else 3,
        "documentation_links": data["docs"],
        "estimated_time": "3-6 hours" if category == "Unreal" else "1-3 hours"
    }
    
    return CodeXRResponse(
        query=query,
        category=category,
        subtasks=subtasks,
        code_snippet=data["main_code"],
        best_practices=data["best_practices"],
        gotchas=data["gotchas"],
        difficulty_rating=4 if category == "Shader" else 3,
        documentation_links=data["docs"],
        estimated_time="3-6 hours" if category == "Unreal" else "1-3 hours",
        raw_json=raw_json
    )

def create_codexr_response(response_json: dict) -> CodeXRResponse:
    """Create CodeXR response from JSON"""
    subtasks = [SubTask(**task) for task in response_json.get("subtasks", [])]
    
    return CodeXRResponse(
        query=response_json.get("query", ""),
        category=response_json.get("category", "General"),
        subtasks=subtasks,
        code_snippet=response_json.get("code_snippet", ""),
        best_practices=response_json.get("best_practices", []),
        gotchas=response_json.get("gotchas", []),
        difficulty_rating=response_json.get("difficulty_rating", 3),
        documentation_links=response_json.get("documentation_links", []),
        estimated_time=response_json.get("estimated_time", "2-4 hours"),
        raw_json=response_json
    )

def generate_fallback_response(query: str, category: str) -> CodeXRResponse:
    """Generate fallback response when LLMs are unavailable"""
    subtasks = [
        SubTask(
            description="Research the specific implementation",
            explanation="Look up official documentation and examples",
            code_snippet="// Check platform-specific documentation"
        )
    ]
    
    raw_json = {
        "query": query,
        "category": category,
        "subtasks": [task.dict() for task in subtasks],
        "code_snippet": f"// Implementation for {category} development\n// Check official documentation for specific examples",
        "best_practices": ["Follow official platform guidelines", "Test on target devices", "Optimize for performance"],
        "gotchas": ["Version compatibility issues", "Platform-specific limitations"],
        "difficulty_rating": 3,
        "documentation_links": ["https://docs.unity3d.com", "https://docs.unrealengine.com"],
        "estimated_time": "2-4 hours"
    }
    
    return CodeXRResponse(
        query=query,
        category=category,
        subtasks=subtasks,
        code_snippet=f"// Implementation for {category} development\n// Check official documentation for specific examples",
        best_practices=["Follow official platform guidelines", "Test on target devices", "Optimize for performance"],
        gotchas=["Version compatibility issues", "Platform-specific limitations"],
        difficulty_rating=3,
        documentation_links=["https://docs.unity3d.com", "https://docs.unrealengine.com"],
        estimated_time="2-4 hours",
        raw_json=raw_json
    )

def process_voice_input() -> Optional[str]:
    """Process voice input using Whisper"""
    try:
        # Audio recorder
        audio_bytes = audio_recorder(
            text="Click to record your query",
            recording_color="#e74c3c",
            neutral_color="#34495e",
            icon_name="microphone",
            icon_size="2x"
        )
        
        if audio_bytes:
            # Save audio to temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                tmp_file.write(audio_bytes)
                tmp_file_path = tmp_file.name
            
            # Load Whisper model
            model = whisper.load_model("base")
            result = model.transcribe(tmp_file_path)
            
            return result["text"]
            
    except Exception as e:
        st.error(f"Voice input error: {e}")
        return None

def render_header():
    """Render main header"""
    st.markdown("""
    <div class="main-header">
        <h1>ü•Ω CodeXR</h1>
        <h3>AI Coding Assistant for AR/VR Developers</h3>
        <p>Breaking down tasks ‚Ä¢ Ready-to-paste code ‚Ä¢ Best practices ‚Ä¢ Documentation links</p>
    </div>
    """, unsafe_allow_html=True)

def render_demo_scenarios():
    """Render demo scenario buttons"""
    st.subheader("üéØ Demo Scenarios")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üéÆ Unity VR Teleportation", key="demo1", help="How do I add teleport locomotion in Unity VR?"):
            st.session_state.demo_query = "How do I add teleport locomotion in Unity VR?"
            st.session_state.demo_category = "Unity"
            
    with col2:
        if st.button("üåê Unreal VR Multiplayer", key="demo2", help="How do I set up multiplayer in Unreal VR?"):
            st.session_state.demo_query = "How do I set up multiplayer in Unreal VR?"
            st.session_state.demo_category = "Unreal"
            
    with col3:
        if st.button("üëÅÔ∏è AR Occlusion Shader", key="demo3", help="Which shader works best for AR occlusion?"):
            st.session_state.demo_query = "Which shader works best for AR occlusion?"
            st.session_state.demo_category = "Shader"

def render_input_section():
    """Render input section with voice/text options"""
    st.subheader("üí¨ Ask CodeXR")
    
    # Voice input option
    with st.expander("üé§ Voice Input (Whisper)"):
        voice_text = process_voice_input()
        if voice_text:
            st.session_state.voice_query = voice_text
            st.success(f"Transcribed: {voice_text}")
    
    # Text input
    default_query = ""
    if hasattr(st.session_state, 'demo_query'):
        default_query = st.session_state.demo_query
    elif hasattr(st.session_state, 'voice_query'):
        default_query = st.session_state.voice_query
        
    query = st.text_area(
        "Enter your AR/VR development question:",
        value=default_query,
        height=100,
        placeholder="How do I implement hand tracking in Unity VR?"
    )
    
    # Category selection
    col1, col2 = st.columns([3, 1])
    
    with col1:
        category = st.selectbox(
            "Category (auto-detected if not selected):",
            ["Auto-detect", "Unity", "Unreal", "Shader", "General"],
            index=0 if not hasattr(st.session_state, 'demo_category') else 
                  ["Auto-detect", "Unity", "Unreal", "Shader", "General"].index(st.session_state.demo_category)
        )
    
    with col2:
        llm_choice = st.selectbox(
            "LLM Backend:",
            ["Gemini 2.5", "GPT-4o-mini", "StarCoder2", "Demo Mode"]
        )
    
    return query, category, llm_choice

def render_results(response: CodeXRResponse):
    """Render the complete results section"""
    st.markdown("---")
    st.subheader("üìã CodeXR Analysis Results")
    
    # Header with metadata
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"**Category:** {response.category}")
    with col2:
        difficulty_class = f"difficulty-{response.difficulty_rating}"
        stars = "‚≠ê" * response.difficulty_rating
        st.markdown(f'<span class="difficulty-badge {difficulty_class}">Difficulty: {stars}</span>', 
                   unsafe_allow_html=True)
    with col3:
        st.markdown(f"**Estimated Time:** {response.estimated_time}")
    
    # Subtasks
    st.subheader("üìù Step-by-Step Guide")
    for i, subtask in enumerate(response.subtasks, 1):
        with st.container():
            st.markdown(f"""
            <div class="subtask-item">
                <h4>{i}. {subtask.description}</h4>
                <p>{subtask.explanation or ''}</p>
                {f'<pre><code>{subtask.code_snippet}</code></pre>' if subtask.code_snippet else ''}
            </div>
            """, unsafe_allow_html=True)
    
    # Main code snippet
    st.subheader("üíª Code Implementation")
    
    # Determine language for syntax highlighting
    language = "csharp"
    if response.category == "Unreal":
        language = "cpp"
    elif response.category == "Shader":
        language = "glsl"
    
    st.code(response.code_snippet, language=language)
    
    # Best practices and gotchas
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("‚úÖ Best Practices")
        for practice in response.best_practices:
            st.markdown(f"""
            <div class="best-practice">
                <strong>‚úì</strong> {practice}
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        st.subheader("‚ö†Ô∏è Gotchas")
        for gotcha in response.gotchas:
            st.markdown(f"""
            <div class="gotcha">
                <strong>‚ö†</strong> {gotcha}
            </div>
            """, unsafe_allow_html=True)
    
    # Documentation links
    st.subheader("üìö Official Documentation")
    for i, link in enumerate(response.documentation_links):
        st.markdown(f"[üìñ Documentation Link {i+1}]({link})")
    
    # Raw JSON output
    with st.expander("üîß Raw JSON Output (for developers)"):
        st.json(response.raw_json)

def render_sidebar():
    """Render sidebar with configuration"""
    with st.sidebar:
        st.markdown("## ‚öôÔ∏è Configuration")
        
        # API Key Status
        st.markdown("### üîë API Status")
        config = Config()
        
        if config.GEMINI_API_KEY:
            st.success("‚úÖ Gemini API")
        else:
            st.warning("‚ö†Ô∏è Gemini API not configured")
            
        if config.OPENAI_API_KEY:
            st.success("‚úÖ OpenAI API")
        else:
            st.warning("‚ö†Ô∏è OpenAI API not configured")
            
        if config.SERP_API_KEY:
            st.success("‚úÖ SERP API")
        else:
            st.warning("‚ö†Ô∏è SERP API not configured")
        
        # Success Criteria Checklist
        st.markdown("### ‚úÖ Success Criteria")
        st.markdown("""
        <div class="success-criteria">
        ‚úÖ Assistant produces structured subtasks and code snippets<br>
        ‚úÖ Results grounded in real docs (via web search)<br>
        ‚úÖ Outputs include best practices + docs link + difficulty rating<br>
        ‚úÖ Streamlit UI demo-ready with at least 3 working queries
        </div>
        """, unsafe_allow_html=True)
        
        # Phase 2 & 3 Preview
        st.markdown("### üöÄ Roadmap")
        st.markdown("""
        **Phase 2: RAG-Lite & Debugging**
        - Offline documentation indexing
        - Error log interpretation
        - Faster, accurate responses
        
        **Phase 3: VS Code Extension**
        - Native IDE integration
        - Direct snippet insertion
        - Real-time debugging support
        """)

def main():
    """Main Streamlit application"""
    
    # Initialize session state
    if 'response_history' not in st.session_state:
        st.session_state.response_history = []
    
    # Initialize APIs
    search_engines = initialize_apis()
    
    # Render UI
    render_header()
    render_sidebar()
    render_demo_scenarios()
    
    # Input section
    query, category, llm_choice = render_input_section()
    
    # Process query
    if st.button("üöÄ Ask CodeXR", type="primary") and query.strip():
        
        with st.spinner("ü§ñ CodeXR is analyzing your query..."):
            
            # Auto-detect category if not specified
            if category == "Auto-detect":
                category = categorize_query(query)
                st.info(f"üéØ Auto-detected category: **{category}**")
            
            # Web search integration
            search_results = search_documentation(query, search_engines)
            
            # LLM processing
            response = process_with_llm(query, category, search_results, llm_choice)
            
            # Store in history
            st.session_state.response_history.append({
                "timestamp": datetime.now(),
                "query": query,
                "response": response
            })
            
            # Render results
            render_results(response)
    
    # Show usage instructions if no query
    if not query.strip():
        st.info("üí° **Getting Started:** Try one of the demo scenarios above or enter your own AR/VR development question!")

if __name__ == "__main__":
    main()
